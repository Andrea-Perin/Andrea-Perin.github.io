<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://andrea-perin.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://andrea-perin.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-20T17:19:18+00:00</updated><id>https://andrea-perin.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">Riemannian distance for SPD circulant matrices</title><link href="https://andrea-perin.github.io/blog/2024/circulant_distance/" rel="alternate" type="text/html" title="Riemannian distance for SPD circulant matrices"/><published>2024-12-19T00:00:00+00:00</published><updated>2024-12-19T00:00:00+00:00</updated><id>https://andrea-perin.github.io/blog/2024/circulant_distance</id><content type="html" xml:base="https://andrea-perin.github.io/blog/2024/circulant_distance/"><![CDATA[<p>I was working on some homework for a course on <em>Geometric Deep Learning</em>. The context was differential geometry, more specifically the manifold of Symmetric Positive Definite (SPD) matrices. The exercise had us thinking about a notion of distance for this manifold. It also was presenting it as an example of the algebraic concept of a <a href="https://en.wikipedia.org/wiki/Convex_cone">convex cone</a>. I was left wondering: where do <em>circulant matrices</em> live in all of this?</p> <h3 id="spd-matrices">SPD matrices</h3> <p>If you end up on this page, I take it for granted you know what a symmetric matrix is. As for the Positive Definite part, the way I think about them is like a “stretching” operator: feed it any vector, and this thing will:</p> <ol> <li>rotate it to “align it” to an orthogonal basis;</li> <li>stretch/scale every component by a strictly positive number;</li> <li>undo the rotation you did at the beginning. Importantly, an positive definite matrix has strictly positive determinant.</li> </ol> <p>More info is <a href="https://en.wikipedia.org/wiki/Definite_matrix">on Wikipedia</a>, of course.</p> <p>You may find SPD matrices in the following contexts:</p> <ul> <li>as <em>covariance matrices</em> (if it is a <em>sample</em> covariance, you may need “enough” samples, so that it is not rank deficient);</li> <li>as <em>metric tensors</em>, once you specify some coordinate system;</li> <li>as <em>Gram matrices</em>, in the context of kernel methods;</li> <li>and, I assume, many more.</li> </ul> <h3 id="the-manifold-of-spd-matrices">The manifold of SPD matrices</h3> <p>Imagine an \(n\times n\) matrix \(\mathcal{M}\) that is symmetric and positive definite. Due to its symmetry, you only actually need to specify \(n(n+1)/2\) elements to characterize the matrix. You can then think of this matrix as a point in the space \(\mathbb{R}^{n(n+1)/2}\). The set of all such points that correspond to a symmetric positive definite matrix forms a <em>manifold</em>. It is possible to endow this manifold with a <em>metric</em>, that is, a way to “measure distance” between two of its points, thus creating a <em>Riemannian manifold</em>. We call this manifold \(\mathcal{S}_{++}^n\).</p> <p>A careful discussion of Riemannian manifolds is a bit outside of my capabilities, but resources are plentiful if you crave some big boy maths.</p> <p>It is instructive and amusing to check what this manifold may look like in practice. Choose \(n=2\), so that matrices (which are symmetric!) are of the type</p> \[\mathcal{M} = \begin{pmatrix} x &amp; z \\ z &amp; y \end{pmatrix}.\] <p>Additionally, we need to satisfy the requirements</p> \[\det \mathcal{M} = xy - z^2 &gt;0, \quad x&gt;0, \quad y&gt;0.\] <p>These are needed for the positive-definiteness requirement. The matrix \(\mathcal{M}\) above can be represented as the point \((x, y, z)\in \mathbb{R}^3\). We can think of the manifold as the following subset of \(\mathbb{R}^3\):</p> \[\mathcal{S}_{++}^2 = \{(x, y, z) \in \mathbb{R}^3 | xy-z^2&gt;0, x&gt;0, y&gt;0\}.\] <p>Feed this to <code class="language-plaintext highlighter-rouge">matplotlib</code>, and you get this:</p> <div class="row mt-3 justify-content-center"> <div class="col-8 mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/posts/circulant_distance/cone.png" alt="The convex cone structure for a 2D SPD matrix."/> </div> </div> <div class="caption"> The convex cone structure for a 2D SPD matrix. </div> <p>This really looks like a <em>geometric</em> cone, and it also happens to be an <a href="https://en.wikipedia.org/wiki/Convex_cone"><em>algebraic</em> cone</a>.</p> <h3 id="distance-between-spd-matrices">Distance between SPD matrices</h3> <p>One can define a notion of distance between two SPD matrices \(P, Q \in \mathcal{S}_{++}^n\), as done in <a href="http://www.ipb.uni-bonn.de/pdfs/Forstner1999Metric.pdf">this paper</a>: The formula looks like this:</p> \[d(P, Q) = \sqrt{\sum_{i=1}^n \ln^2 \lambda_i(P, Q)},\] <p>where \(\lambda_i(P, Q)\) denotes the \(i\)-th eigenvalue that can be obtained by solving the equation</p> \[\det(\lambda P - Q) = 0.\] <h4 id="geodesics">Geodesics</h4> <p>Similarly, we can define a <em>geodesic</em> between two SPD matrices, \(P, Q \in \mathcal{S}_{++}^n\), with the following formula:</p> \[\gamma(t) = P^{1/2}(P^{-1/2}QP^{-1/2})^tP^{1/2}, \quad t\in[0,1].\] <p>For any \(t\in[0, 1]\), \(\gamma(t)\) is an SPD matrix. Here is some <code class="language-plaintext highlighter-rouge">JAX</code> code to get this geodesic:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">jax</span>
<span class="kn">from</span> <span class="n">jax</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">jnp</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Callable</span>


<span class="k">def</span> <span class="nf">get_geodesic</span><span class="p">(</span><span class="n">P</span><span class="p">:</span> <span class="n">jax</span><span class="p">.</span><span class="n">Array</span><span class="p">,</span> <span class="n">Q</span><span class="p">:</span> <span class="n">jax</span><span class="p">.</span><span class="n">Array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
    <span class="n">Op</span><span class="p">,</span> <span class="n">Sp</span><span class="p">,</span> <span class="n">OpT</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">svd</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">Phalf</span> <span class="o">=</span> <span class="p">(</span><span class="n">Op</span> <span class="o">*</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">Sp</span><span class="p">))</span> <span class="o">@</span> <span class="n">OpT</span>
    <span class="n">Pmhalf</span> <span class="o">=</span> <span class="p">(</span><span class="n">Op</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">jnp</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">Sp</span><span class="p">)))</span> <span class="o">@</span> <span class="n">OpT</span>
    <span class="nb">pow</span> <span class="o">=</span> <span class="n">Pmhalf</span> <span class="o">@</span> <span class="n">Q</span> <span class="o">@</span> <span class="n">Pmhalf</span>
    <span class="n">Opow</span><span class="p">,</span> <span class="n">Spow</span><span class="p">,</span> <span class="n">OpowT</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">svd</span><span class="p">(</span><span class="nb">pow</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">gamma</span><span class="p">(</span><span class="n">t</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jax</span><span class="p">.</span><span class="n">Array</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Phalf</span> <span class="o">@</span> <span class="p">((</span><span class="n">Opow</span> <span class="o">*</span> <span class="p">(</span><span class="n">Spow</span><span class="o">**</span><span class="n">t</span><span class="p">))</span> <span class="o">@</span> <span class="n">OpowT</span><span class="p">)</span> <span class="o">@</span> <span class="n">Phalf</span>
    <span class="k">return</span> <span class="n">gamma</span>


<span class="c1"># example usage
</span><span class="n">P1</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span> <span class="p">)</span>
<span class="n">Q1</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span> <span class="p">)</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="nf">get_geodesic</span><span class="p">(</span><span class="n">P1</span><span class="p">,</span> <span class="n">Q1</span><span class="p">)</span>
<span class="n">times</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="nf">vmap</span><span class="p">(</span><span class="n">gamma</span><span class="p">)(</span><span class="n">times</span><span class="p">)</span></code></pre></figure> <p>Using this code and a bit of 3D plotting, we get this gif, showing a few geodesics in the \(\mathcal{S}_{++}^2\) manifold.</p> <div class="row mt-3 justify-content-center"> <div class="col-8 mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/posts/circulant_distance/geodesic.gif" alt="Geodesics in the SPD manifold."/> </div> </div> <div class="caption"> A few geodesics in the $$\mathcal{S}_{++}^2$$ manifold. </div> <h3 id="circulant-matrices">Circulant matrices</h3> <p>Now, let’s move to <a href="https://en.wikipedia.org/wiki/Circulant_matrix">circulant matrices</a> that also happen to be SPD.</p> <p>Let us start from the case \(n=2\). A 2 by 2, positive definite circulant matrix can be written as</p> \[\mathcal{M} = \begin{pmatrix} x &amp; z \\ z &amp; x \end{pmatrix},\] <p>with \(x&gt;0\) and \(|z| &lt; x\). This is a manifold, too! I will call it \(\mathcal{C}_{++}^2\); this is a 2D manifold (one fewer dimension than \(\mathcal{S}_{++}^2\)). Specifically, it can be visualized as a slice of the cone above, obtained by intersecting it with the plane \(x=y\). This is, again, a cone (at least algebraically speaking; I guess it is also geometrically a 2D cone). We can now visualize the geodesics between circulant matrices on a 2D plane.</p> <div class="row mt-3 justify-content-center"> <div class="col-8 mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/posts/circulant_distance/circ_cone.png" alt="Geodesics in the circulant cone."/> </div> </div> <div class="caption"> A few geodesics in the $\mathcal{C}_{++}^2$ manifold. </div> <h3 id="geodesic-formula-for-mathcalc_n">Geodesic formula for \(\mathcal{C}_{++}^n\)</h3> <p>We can just reuse the geodesic formula for \(\mathcal{S}_{++}^n\) and specialize it to the submanifold of circulant matrices. Consider \(P, Q \in \mathcal{C}_{++}^n\); these are diagonalized by the <a href="https://en.wikipedia.org/wiki/Discrete_Fourier_transform">DFT matrix</a>, \(\mathcal{F}\):</p> \[P = \mathcal{F} \Lambda_P \mathcal{F}^{-1}, \quad Q = \mathcal{F} \Lambda_Q \mathcal{F}^{-1}.\] <p>Then, we get an easier expression for \(\gamma: [0, 1] \to \mathcal{C}_{++}^n\):</p> \[\gamma(t) = \mathcal{F} \frac{\Lambda_Q^t}{\Lambda_P^{t-1}} \mathcal{F}^{-1},\] <p>where the ratio and the power operation are understood to happen elementwise. As a sanity check, we see that \(\gamma(0) = P\) and \(\gamma(1) = Q\), as expected. The code for this geodesic is a tiny bit cleaner, as well:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">jax</span>
<span class="kn">from</span> <span class="n">jax</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">jnp</span><span class="p">,</span> <span class="n">vmap</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Callable</span>


<span class="k">def</span> <span class="nf">get_circ_geodesic</span><span class="p">(</span><span class="n">P</span><span class="p">:</span> <span class="n">jax</span><span class="p">.</span><span class="n">Array</span><span class="p">,</span> <span class="n">Q</span><span class="p">:</span> <span class="n">jax</span><span class="p">.</span><span class="n">Array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
    <span class="n">lp</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="n">fft</span><span class="p">.</span><span class="nf">rfft</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">lq</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="n">fft</span><span class="p">.</span><span class="nf">rfft</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">gamma</span><span class="p">(</span><span class="n">t</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jax</span><span class="p">.</span><span class="n">Array</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">jnp</span><span class="p">.</span><span class="n">fft</span><span class="p">.</span><span class="nf">irfft</span><span class="p">(</span><span class="n">lp</span><span class="o">**</span><span class="n">t</span> <span class="o">/</span> <span class="n">lq</span><span class="o">**</span><span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">gamma</span>


<span class="c1"># example usage
</span><span class="n">P1</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span> <span class="p">)</span>
<span class="n">Q1</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span> <span class="p">)</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="nf">get_circ_geodesic</span><span class="p">(</span><span class="n">P1</span><span class="p">,</span> <span class="n">Q1</span><span class="p">)</span>
<span class="n">times</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="nf">vmap</span><span class="p">(</span><span class="n">gamma</span><span class="p">)(</span><span class="n">times</span><span class="p">)</span></code></pre></figure> <h3 id="distances">Distances</h3> <p>What about the distance between two circulant matrices? Again, we can just take the definition of distance that holds for generic SPD matrices, and use the properties of circulant matrices. We get</p> \[d(P, Q)^2 = \sum_i \left(\ln\frac{(\Lambda_P)_i}{(\Lambda_Q)_i}\right)^2,\] <p>where \(\Lambda_P, \Lambda_Q\) are the spectra of the matrices \(P, Q\) (in other words, their DFT). After slight manipulation, this expression looks a lot like a usual Euclidean distance:</p> \[d(P, Q)^2 = \sum_i \left(\ln(\Lambda_P)_i - \ln(\Lambda_Q)_i\right)^2,\] <p>so a sum of squared <em>log-distances</em> between eigenvalues.</p> <p>TODO: find analogies in signal processing maybe?</p> <h3 id="open-questions">Open questions</h3> <p>I have one question left at the moment (hopefully, more will arise). The question is: take a matrix \(P \in \mathcal{S}_{++}^n\); what is the <em>closest</em> matrix \(Q \in \mathcal{C}_{++}^n\)? The idea has something to do with <a href="https://arxiv.org/abs/2412.11521">our recent paper</a>, where we use an <em>ex-post</em> circularization procedure on Gram matrices. This circularization happens by simply averaging the diagonals of the Gram matrix. At first glance, it seems like there is no other way to make a matrix circulant that would make much sense. So it would be nice to see if it just so happens that this diagonal-averaged matrix is the “orthogonal projection” of an SPD matrix onto the submanifold of circulant SPD matrices. A possible plan of attack would be to minimize the length between an arbitrary SPD matrix $P$ and a target circulant SPD matrix \(Q\). I will maybe do that in the next days.</p> <h3 id="references">References</h3> <p>A list of references:</p> <ul> <li>a definition of distance between SPD matrices: <a href="http://www.ipb.uni-bonn.de/pdfs/Forstner1999Metric.pdf">http://www.ipb.uni-bonn.de/pdfs/Forstner1999Metric.pdf</a></li> <li>our recent paper: <a href="https://arxiv.org/abs/2412.11521">https://arxiv.org/abs/2412.11521</a></li> <li>the code for generating the plots can be found <a href="https://gist.github.com/Andrea-Perin/1f268c1655db3cc848474375012f4496">here</a></li> </ul>]]></content><author><name></name></author><category term="maths"/><summary type="html"><![CDATA[Or slicing cones]]></summary></entry><entry><title type="html">Tail function of the multivariate Gaussian distribution</title><link href="https://andrea-perin.github.io/blog/2024/tail-mvg/" rel="alternate" type="text/html" title="Tail function of the multivariate Gaussian distribution"/><published>2024-01-30T00:00:00+00:00</published><updated>2024-01-30T00:00:00+00:00</updated><id>https://andrea-perin.github.io/blog/2024/tail-mvg</id><content type="html" xml:base="https://andrea-perin.github.io/blog/2024/tail-mvg/"><![CDATA[<p>As one often does, I was wondering what an \(N\)-dimensional generalisation of the Gaussian tail function is.</p> <h3 id="the-result">The result</h3> <p>For a distribution \(\mathcal{N}(\mu, \Sigma)\) and an affine hyperplane \(\{w, b\}\), the portion of distribution to the right of the hyperplane is \(H\left(\frac{-b-w\cdot \mu}{\sqrt{w^T\Sigma w}}\right)\).</p> <h3 id="derivation">Derivation</h3> <p>The <em>tail function</em> of a Gaussian distribution \(\mathcal{N}(0, 1)\) is defined as</p> \[H(x) = \int_x^\infty \frac{ds}{\sqrt{2\pi}} \exp\left(-\frac{s^2}{2}\right),\] <p>and it quantifies the volume of the distribution that lies to the right of the value \(x\).</p> <p>Let us consider a hyperplane defined by \(w \in \mathbb{R}^N\) and a bias value \(b\in\mathbb{R}\). Together, they define an affine subspace that may be thought of as a separator. We are interested in how much of the multivariate Gaussian distribution \(\mathcal{N}(\mu, \Sigma)\) lies on one side of this subspace.</p> <p>Let us call this quantity \(V\), which we expect to be a function of the affine subspace \(\{w, b\}\) as well as of the distribution parameters \(\{\mu, \Sigma\}\). We can compute \(V\) as follows:</p> \[V(w, b, \mu, \Sigma) = \int_{\mathbb{R}^N} \frac{d^Nx}{(2\pi)^{-N/2}\sqrt{\det \Sigma}} \theta(x\cdot w + b) \exp\left(-\frac{1}{2} (x-\mu)^T\Sigma^{-1}(x-\mu)\right).\] <p>The Heaviside Theta acts as a sort of indicator function, specifying which part of the domain \(\mathbb{R}^N\) we are actually interested in, while the Gaussian part weights this portion by the appropriate amount. Now, the trick is to consider the following expression for the Heaviside Theta:</p> \[\Theta(x+\alpha) = \int_{-\alpha}^{\infty} \frac{d\lambda}{2\pi} \int d\gamma \exp(i \gamma (\lambda - x)).\] <p>I like to think of this expression as a “stack of Dirac deltas” extending over the range where the argument of the Theta function is positive, that is, \(x\in(-\alpha, \infty)\).</p> <p>The overall formula becomes</p> \[V(w, b, \mu, \Sigma) = \int_{\mathbb{R}^N} \frac{d^Nx}{(2\pi)^{-N/2}\sqrt{\det \Sigma}} \int_{-b}^{\infty} \frac{d\lambda}{2\pi} \int d\gamma \exp(i \gamma (\lambda - x\cdot w)) \exp\left(-\frac{1}{2} (x-\mu)^T\Sigma^{-1}(x-\mu)\right).\] <p>It is now just a matter of Gaussian integration. Starting first from the \(x\), and changing integration variable to \(z = x-\mu\), we obtain</p> \[V(w, b, \mu, \Sigma) = \int_{-b}^{\infty} \frac{d\lambda}{2\pi} \int d\gamma \exp\left(-\frac{1}{2} \gamma^2 (w^T\Sigma w) + i \gamma (\lambda - w\cdot \mu)\right).\] <p>Now we integrate over \(\gamma\), obtaining</p> \[V(w, b, \mu, \Sigma) = \int_{-b}^{\infty} \frac{d\lambda}{2\pi} \sqrt{\frac{2\pi}{w^T\Sigma w}} \exp\left(-\frac{1}{2}\left(\frac{\lambda - w\cdot \mu}{\sqrt{w^T\Sigma w}}\right)^2\right).\] <p>Changing variable to \(s = \frac{\lambda - w\cdot \mu}{\sqrt{w^T\Sigma w}}\), we obtain the formula</p> \[V(w, b, \mu, \Sigma) = \int_{\frac{-b-w\cdot \mu}{\sqrt{w^T\Sigma w}}}^{\infty} \frac{ds}{\sqrt{2\pi}} \exp\left(-\frac{s^2}{2}\right) = H\left(\frac{-b-w\cdot \mu}{\sqrt{w^T\Sigma w}}\right),\] <p>which is the final result.</p> <h3 id="disclaimer">Disclaimer</h3> <p>There is probably a much cleaner derivation that makes use of affine transformations to turn a general \(\mathcal{N}(\mu, \Sigma)\) Multivariate Gaussian into a more wieldy \(\mathcal{N}(0, \Sigma')\).</p> <h3 id="code-check">Code check</h3> <p>Here’s a quick JAX-based implementation to check that the results make sense.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="sh">"""</span><span class="s">Multivariate tail function</span><span class="sh">"""</span>
<span class="kn">from</span> <span class="n">jax</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">jnp</span><span class="p">,</span> <span class="n">random</span> <span class="k">as</span> <span class="n">jr</span>
<span class="kn">from</span> <span class="n">jax.scipy.special</span> <span class="kn">import</span> <span class="n">erf</span>


<span class="k">def</span> <span class="nf">H</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="nf">erf</span><span class="p">(</span><span class="n">x</span><span class="o">/</span><span class="n">jnp</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>


<span class="n">N</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># dimension
</span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">126</span>
<span class="n">RNG</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nc">PRNGKey</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>


<span class="c1"># define parameters of Gaussian
</span><span class="n">RNG</span><span class="p">,</span> <span class="n">cov_key</span><span class="p">,</span> <span class="n">mean_key</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">RNG</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">mean_key</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">D</span><span class="p">,))</span>
<span class="n">precov</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">cov_key</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">D</span><span class="p">))</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">precov</span> <span class="o">@</span> <span class="n">precov</span><span class="p">.</span><span class="n">T</span>  <span class="c1"># making sure the cov is (at least) PSD
# define separator
</span><span class="n">RNG</span><span class="p">,</span> <span class="n">w_key</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">RNG</span><span class="p">)</span>
<span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="o">*</span><span class="n">w</span><span class="p">)</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">w_key</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">D</span><span class="o">+</span><span class="mi">1</span><span class="p">,))</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>


<span class="c1"># sample from this gaussian
</span><span class="n">RNG</span><span class="p">,</span> <span class="n">p_key</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">RNG</span><span class="p">)</span>
<span class="n">points</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">multivariate_normal</span><span class="p">(</span><span class="n">p_key</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="p">))</span>


<span class="c1"># experimental fraction
</span><span class="n">emp</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">points</span> <span class="o">@</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">theory</span> <span class="o">=</span> <span class="nc">H</span><span class="p">((</span><span class="o">-</span><span class="n">b</span><span class="o">-</span><span class="n">w</span><span class="nd">@mean</span><span class="p">)</span><span class="o">/</span><span class="n">jnp</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">jnp</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span><span class="sh">'</span><span class="s">i,ij,j</span><span class="sh">'</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">w</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Empirical: </span><span class="si">{</span><span class="n">emp</span><span class="si">}</span><span class="se">\n</span><span class="s">Theory: </span><span class="si">{</span><span class="n">theory</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span></code></pre></figure>]]></content><author><name></name></author><category term="stats"/><summary type="html"><![CDATA[Or splitting clouds]]></summary></entry></feed>