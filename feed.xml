<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://andrea-perin.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://andrea-perin.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-01-30T23:32:38+00:00</updated><id>https://andrea-perin.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">Tail function of a Multivariate Gaussian distribution</title><link href="https://andrea-perin.github.io/blog/2024/tail-mvg/" rel="alternate" type="text/html" title="Tail function of a Multivariate Gaussian distribution"/><published>2024-01-30T16:38:46+00:00</published><updated>2024-01-30T16:38:46+00:00</updated><id>https://andrea-perin.github.io/blog/2024/tail-mvg</id><content type="html" xml:base="https://andrea-perin.github.io/blog/2024/tail-mvg/"><![CDATA[<p>As one often does, I was wondering what an \(N\)-dimensional generalisation of the Gaussian tail function is.</p> <h3 id="the-result">The result</h3> <p>For a distribution \(\mathcal{N}(\mu, \Sigma)\) and an affine hyperplane \(\{w, b\}\), the portion of distribution to the right of the hyperplane is \(H\left(\frac{-b-w\cdot \mu}{\sqrt{w^T\Sigma w}}\right)\).</p> <h3 id="derivation">Derivation</h3> <p>The <em>tail function</em> of a Gaussian distribution \(\mathcal{N}(0, 1)\) is defined as</p> \[H(x) = \int_x^\infty \frac{ds}{\sqrt{2\pi}} \exp\left(-\frac{s^2}{2}\right),\] <p>and it quantifies the volume of the distribution that lies to the right of the value \(x\).</p> <p>Let us consider a hyperplane defined by \(w \in \mathbb{R}^N\) and a bias value \(b\in\mathbb{R}\). Together, they define an affine subspace that may be thought of as a separator. We are interested in how much of the multivariate Gaussian distribution \(\mathcal{N}(\mu, \Sigma)\) lies on one side of this subspace.</p> <p>Let us call this quantity \(V\), which we expect to be a function of the affine subspace \(\{w, b\}\) as well as of the distribution parameters \(\{\mu, \Sigma\}\). We can compute \(V\) as follows:</p> \[V(w, b, \mu, \Sigma) = \int_{\mathbb{R}^N} \frac{d^nx}{(2\pi)^{-N/2}\sqrt{\det \Sigma}} \theta(x\cdot w + b) \exp\left(-\frac{1}{2} (x-\mu)^T\Sigma^{-1}(x-\mu)\right).\] <p>The Heaviside Theta acts as a sort of indicator function, specifying which part of the domain \(\mathbb{R}^N\) we are actually interested in, while the Gaussian part weights this portion by the appropriate amount. Now, the trick is to consider the following expression for the Heaviside Theta:</p> \[\Theta(x+\alpha) = \int_{-\alpha}^{\infty} \frac{d\lambda}{2\pi} \int d\gamma \exp(i \gamma (\lambda - x)).\] <p>Notice how this is a double integral; the one over \(\lambda\) shows ??? I like to think of this expression as a “stack of Dirac deltas” extending over the range where the argument of the Theta function is positive, that is, \(x\in(-\alpha, \infty)\).</p> <p>The overall formula becomes</p> \[V(w, b, \mu, \Sigma) = \int_{\mathbb{R}^N} \frac{d^nx}{(2\pi)^{-N/2}\sqrt{\det \Sigma}} \int_{-b}^{\infty} \frac{d\lambda}{2\pi} \int d\gamma \exp(i \gamma (\lambda - x\cdot w)) \exp\left(-\frac{1}{2} (x-\mu)^T\Sigma^{-1}(x-\mu)\right).\] <p>It is now just a matter of Gaussian integration. Starting first from the \(x\), and changing integration variable to \(z = x-\mu\), we obtain</p> \[V(w, b, \mu, \Sigma) = \int_{-b}^{\infty} \frac{d\lambda}{2\pi} \int d\gamma \exp\left(-\frac{1}{2} \gamma^2 (w^T\Sigma w) + i \gamma (\lambda - w\cdot \mu)\right).\] <p>Now we integrate over \(\gamma\), obtaining</p> \[V(w, b, \mu, \Sigma) = \int_{-b}^{\infty} \frac{d\lambda}{2\pi} \sqrt{\frac{2\pi}{w^T\Sigma w}} \exp\left(-\frac{1}{2}\left(\frac{\lambda - w\cdot \mu}{\sqrt{w^T\Sigma w}}\right)^2\right).\] <p>Changing variable to \(s = \frac{\lambda - w\cdot \mu}{\sqrt{w^T\Sigma w}}\), we obtain the formula</p> \[V(w, b, \mu, \Sigma) = \int_{\frac{-b-w\cdot \mu}{\sqrt{w^T\Sigma w}}}^{\infty} \frac{ds}{\sqrt{2\pi}} \exp\left(-\frac{s^2}{2}\right) = H\left(\frac{-b-w\cdot \mu}{\sqrt{w^T\Sigma w}}\right),\] <p>which is the final result.</p> <h3 id="disclaimer">Disclaimer</h3> <p>There is probably a much cleaner derivation that makes use of affine transformations to turn a general \(\mathcal{N}(\mu, \Sigma)\) Multivariate Gaussian into a more wieldy \(\mathcal{N}(0, \Sigma')\).</p> <h3 id="code-check">Code check</h3> <p>Here’s a quick JAX-based implementation to check that the results make sense.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="sh">"""</span><span class="s">Multivariate tail function</span><span class="sh">"""</span>
<span class="kn">from</span> <span class="n">jax</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">jnp</span><span class="p">,</span> <span class="n">random</span> <span class="k">as</span> <span class="n">jr</span>
<span class="kn">from</span> <span class="n">jax.scipy.special</span> <span class="kn">import</span> <span class="n">erf</span>


<span class="k">def</span> <span class="nf">H</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="nf">erf</span><span class="p">(</span><span class="n">x</span><span class="o">/</span><span class="n">jnp</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>


<span class="n">N</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># dimension
</span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">126</span>
<span class="n">RNG</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nc">PRNGKey</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>


<span class="c1"># define parameters of Gaussian
</span><span class="n">RNG</span><span class="p">,</span> <span class="n">cov_key</span><span class="p">,</span> <span class="n">mean_key</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">RNG</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">mean_key</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">D</span><span class="p">,))</span>
<span class="n">precov</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">cov_key</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">D</span><span class="p">))</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">precov</span> <span class="o">@</span> <span class="n">precov</span><span class="p">.</span><span class="n">T</span>  <span class="c1"># making sure the cov is (at least) PSD
# define separator
</span><span class="n">RNG</span><span class="p">,</span> <span class="n">w_key</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">RNG</span><span class="p">)</span>
<span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="o">*</span><span class="n">w</span><span class="p">)</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">w_key</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">D</span><span class="o">+</span><span class="mi">1</span><span class="p">,))</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>


<span class="c1"># sample from this gaussian
</span><span class="n">RNG</span><span class="p">,</span> <span class="n">p_key</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">RNG</span><span class="p">)</span>
<span class="n">points</span> <span class="o">=</span> <span class="n">jr</span><span class="p">.</span><span class="nf">multivariate_normal</span><span class="p">(</span><span class="n">p_key</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="p">))</span>


<span class="c1"># experimental fraction
</span><span class="n">emp</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">points</span> <span class="o">@</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">theory</span> <span class="o">=</span> <span class="nc">H</span><span class="p">((</span><span class="o">-</span><span class="n">b</span><span class="o">-</span><span class="n">w</span><span class="nd">@mean</span><span class="p">)</span><span class="o">/</span><span class="n">jnp</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">jnp</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span><span class="sh">'</span><span class="s">i,ij,j</span><span class="sh">'</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">w</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Empirical: </span><span class="si">{</span><span class="n">emp</span><span class="si">}</span><span class="se">\n</span><span class="s">Theory: </span><span class="si">{</span><span class="n">theory</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span></code></pre></figure>]]></content><author><name></name></author><category term="random"/><category term="stats"/><category term="gaussian"/><summary type="html"><![CDATA[Splitting clouds]]></summary></entry></feed>